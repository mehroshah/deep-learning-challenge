{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Downloads\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(['EIN','NAME'],axis=1,inplace=True)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "apt_cat = application_df.dtypes.index.tolist()\n",
    "application_df[apt_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_type_count = application_df['APPLICATION_TYPE'].value_counts()\n",
    "app_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Other      804\n",
       "T8         737\n",
       "T7         725\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(app_type_count[app_type_count<600].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_count = application_df['CLASSIFICATION'].value_counts()\n",
    "class_count.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(class_count[class_count < 300].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       1   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    1                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "4                         0                    1                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "34298                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "1                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "4                        0                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "34298                    0                    0                    0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                      0                       0                         0   \n",
       "1                      1                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       1                         0   \n",
       "4                      0                       0                         1   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                  0                       0                         0   \n",
       "34295                  0                       0                         0   \n",
       "34296                  0                       0                         0   \n",
       "34297                  0                       0                         0   \n",
       "34298                  0                       0                         0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                       0                 0                       0   \n",
       "1                       0                 0                       0   \n",
       "2                       0                 0                       0   \n",
       "3                       0                 0                       0   \n",
       "4                       0                 0                       0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                   0                 0                       0   \n",
       "34295                   0                 0                       0   \n",
       "34296                   0                 0                       0   \n",
       "34297                   0                 0                       0   \n",
       "34298                   0                 1                       0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                    0                  0                         1   \n",
       "1                    0                  0                         1   \n",
       "2                    0                  0                         1   \n",
       "3                    0                  0                         1   \n",
       "4                    0                  0                         1   \n",
       "...                ...                ...                       ...   \n",
       "34294                0                  0                         1   \n",
       "34295                0                  0                         1   \n",
       "34296                0                  0                         1   \n",
       "34297                0                  0                         1   \n",
       "34298                0                  0                         1   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "...                         ...  \n",
       "34294                         0  \n",
       "34295                         0  \n",
       "34296                         0  \n",
       "34297                         0  \n",
       "34298                         0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "numeric_app_df = pd.get_dummies(application_df)\n",
    "numeric_app_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = numeric_app_df[\"IS_SUCCESSFUL\"]\n",
    "X = numeric_app_df.drop([\"IS_SUCCESSFUL\"],axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Downloads\\anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 9)                 396       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 496 (1.94 KB)\n",
      "Trainable params: 496 (1.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer = 9\n",
    "hidden_nodes_layer2 = 18\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer ,input_dim=number_input_features,activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer,activation = \"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Downloads\\anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Downloads\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Downloads\\anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "804/804 [==============================] - 3s 2ms/step - loss: 0.6029 - accuracy: 0.6932\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5617 - accuracy: 0.7268\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5566 - accuracy: 0.7292\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5542 - accuracy: 0.7306\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5528 - accuracy: 0.7312\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5518 - accuracy: 0.7326\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5512 - accuracy: 0.7323\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5509 - accuracy: 0.7313\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7326\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5493 - accuracy: 0.7320\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7331\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7325\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7325\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7325\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7339\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7329\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7345\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7339\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7336\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7339\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7338\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7340\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7340\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7343\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7336\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7339\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7346\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7336\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7348\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7346\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7345\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7350\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7350\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7345\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7345\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5447 - accuracy: 0.7352\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7353\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7345\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7343\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7348\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7354\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7346\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7343\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7343\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7350\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7351\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7353\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7354\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7357\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7345\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7357\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7355\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7345\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7362\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7357\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7357\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7358\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7360\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7358\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7362\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7358\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7361\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7362\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7365\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7353\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7358\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7356\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7361\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7359\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7363\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7362\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7353\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7364\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7358\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7359\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7362\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7362\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7359\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7364\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7362\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7356\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7366\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7353\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7355\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7352\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7365\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7360\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7357\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7369\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7362\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7367\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7364\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7357\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5519 - accuracy: 0.7252 - 639ms/epoch - 2ms/step\n",
      "Loss: 0.551851749420166, Accuracy: 0.7252478003501892\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOTT ACCURACY\n",
    "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "history_df.plot(y='accuracy')                          \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export our model to HDF5 file\n",
    "#This is Attempt #1\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "\n",
    "Loss: 0.5536191259042167, Accuracy: 0.727580189704895\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "I need to make some changes in order to get to 75% accuracy.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "\n",
    "Loss: 0.5522796763553564, Accuracy: 0.7250145673751831\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "Loss: 0.5575985619278065, Accuracy: 0.7231487035751343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS:\n",
    "\n",
    "This is Attempt #1\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "\n",
    "Loss: 0.5536191259042167, Accuracy: 0.727580189704895\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "I need to make some changes in order to get to 75% accuracy.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "\n",
    "Loss: 0.5522796763553564, Accuracy: 0.7250145673751831\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "\n",
    "Loss: 0.5575985619278065, Accuracy: 0.7231487035751343\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt#2\n",
    "Application_type cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "layer3 = 27 : activation function = relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# number_input_features = len(X_train_scaled[0])\n",
    "# hidden_nodes_layer1 = 9\n",
    "# hidden_nodes_layer2 = 18\n",
    "# hidden_nodes_layer3 = 27\n",
    "\n",
    "# nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "# nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "# nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "# y_test = np.array(y_test)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "# fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the accuracy\n",
    "# history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "# history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "# nn.save('Models/AlphabetSoupCharity2.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "This is Attempt #2\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "layer3 = 27 : activation function = relu\n",
    "\n",
    "Loss: 0.5541777287836325, Accuracy: 0.7258309125900269\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "Still not at 75% accuracy. Will try something drastic next.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.5545361445735565, Accuracy: 0.7241982221603394\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.5560268456039207, Accuracy: 0.7268804907798767"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attempt #3 -- changing the activation functions\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = tanh\n",
    "layer3 = 27 : activation function = tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# number_input_features = len(X_train_scaled[0])\n",
    "# hidden_nodes_layer1 = 9\n",
    "# hidden_nodes_layer2 = 18\n",
    "# hidden_nodes_layer3 = 27\n",
    "\n",
    "# nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "# nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "# nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "# y_test = np.array(y_test)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "# fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the accuracy\n",
    "# history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "# history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "# nn.save('Models/AlphabetSoupCharity3.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i RESULTS:\n",
    "\n",
    "This is Attempt #3\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = tanh\n",
    "layer3 = 27 : activation function = tanh\n",
    "\n",
    "Loss: 0.5513413424950647, Accuracy: 0.7266472578048706\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "Still not at 75% accuracy. I give up.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.5520951250065173, Accuracy: 0.7255976796150208\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.555375917367963, Accuracy: 0.7251312136650085\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
